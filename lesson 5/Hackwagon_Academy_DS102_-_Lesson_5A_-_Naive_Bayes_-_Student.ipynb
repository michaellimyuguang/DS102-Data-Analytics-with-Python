{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i2.wp.com/hackwagon.com/wp-content/uploads/2017/02/Logo-Web-Export.png?ssl=1\" width=200/></center>\n",
    "<h1> Hackwagon Academy DS102 Lesson 5A </h1>\n",
    "<h2> Näive Bayes Classification</h2> \n",
    "<h3> Lesson Outline </h3>\n",
    "\n",
    "- 1. [Näive Bayes Classification](#1)\n",
    "    - 1.1 [Problem Setup](#1.1)\n",
    "    - 1.2 [Derivation](#1.2)\n",
    "- 2. [Vectorizer](#2)\n",
    "- 3. [Applied Naive Bayes - Popcorn Reviews](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\michael\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\michael\\anaconda3\\lib\\site-packages (from sklearn) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\michael\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\michael\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\michael\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "<a id='1'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;</font><font color=\"salmon\"> Scikit Learn - SKLearn </font> </h2></a>\n",
    "\n",
    "<a id='1.1'><h3>5 Standard Steps</h3></a>\n",
    "\n",
    "**Step 1**: Choose a class of machine learning model from the library \n",
    "\n",
    "**Step 2**: Choose the model’s hyperparameters by instantiating with desired values (tuning)\n",
    "\n",
    "**Step 3**: Arrange data into features and target\n",
    "\n",
    "**Step 4**: Fit model to your data by using the fit() method of the model \n",
    "\n",
    "**Step 5**: Apply the model to new data:\n",
    "    - For supervised learning, using the predict() method\n",
    "    - For unsupervised learning, using the predict() or transform() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;1.</font><font color=\"salmon\"> Näive Bayes Classification </font> </h2></a>\n",
    "\n",
    "We now extend sentiment analysis to texts that we have never seen before, and use a machine learning algorithm - Naïve Bayes Classification - to help us predict if a newly received review has positive or negative sentiment. Naïve Bayes Classification is the first machine learning algorithm we will learn in DS102.\n",
    "\n",
    "<a id='1.1'><h3> 1.1 Problem Setup</h3></a>\n",
    "\n",
    "Consider you have the following documents and their tagged sentiment **class**. $1$ represents a positive sentiment while $0$ represents a negative sentiment. There are only 2 possible classes in this problem.\n",
    "\n",
    "|ID | Text | Sentiment\n",
    "|---|---|--\n",
    "|1|`enjoy like`|$1$\n",
    "|2|`enjoy funny happy`|$1$\n",
    "|3|`hate boring like`|$0$\n",
    "|4|`like happy`|$1$\n",
    "|5|`boring dull`|$0$\n",
    "\n",
    "We now have a new document which is `like happy`. What is the predicted class of this new document?\n",
    "\n",
    "### Getting Probabilities for each Word\n",
    "\n",
    "<img src=\"https://i.imgur.com/RLlZWWp.png\" />\n",
    "\n",
    "Note, adding 1 to the numerator and |V| to the is known as <b>Laplace Smoothing</b>. \n",
    "\n",
    "**Example**\n",
    "\n",
    "```\n",
    "Categories\n",
    "Positive -> 1\n",
    "Negative -> 0\n",
    "\n",
    "Vocabularly = { enjoy, like, funny, happy, hate, boring, like }\n",
    "Number of Words in Vocab = 7\n",
    "\n",
    "Words in Positive Documents = [\n",
    "    enjoy like,\n",
    "    enjoy funny happy,\n",
    "    like happy\n",
    "]\n",
    "Number of words in Positive Documents = 7\n",
    "\n",
    "Words in Negative Documents = [\n",
    "    hate boring like\n",
    "    boring dull\n",
    "]\n",
    "Number of words in negative documents = 7\n",
    "\n",
    "```\n",
    "$$\n",
    "P(\\text{enjoy}|Negative) = \\frac{0 + 1}{5 + 7} = \\frac{1}{12}\n",
    "$$\n",
    "<br/>\n",
    "<br/>\n",
    "$$\n",
    "P(\\text{enjoy}|Positive) = \\frac{2 + 1}{7 + 7} = \\frac{3}{14}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Trained Result\n",
    "\n",
    "|Word | P(W given Positive)| P(W given Negative)|\n",
    "|---|---|--\n",
    "|`boring`|$\\frac{1}{14}$|$\\frac{3}{12}$\n",
    "|`dull`|$\\frac{1}{14}$ |$\\frac{2}{12}$\n",
    "|`enjoy`|$\\frac{3}{14}$ |$\\frac{1}{12}$\n",
    "|`funny`|$\\frac{2}{14}$|$\\frac{1}{12}$\n",
    "|`happy`|$\\frac{3}{14}$|$\\frac{1}{12}$\n",
    "|`hate`|$\\frac{1}{14}$|$\\frac{2}{12}$\n",
    "|`like`|$\\frac{3}{14}$|$\\frac{2}{12}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Bayes Theorem \n",
    "\n",
    "#### Let's take the word 'happy' for example\n",
    "\n",
    "<img src=\"https://i.imgur.com/XDfjIDR.png\" />\n",
    "\n",
    "### Let's say we have 100 texts\n",
    "\n",
    "Number inside the boxes are how many texts fall into that category\n",
    "\n",
    "<img src=\"https://i.imgur.com/RQsgqBr.png\" />\n",
    "\n",
    "#### For Multiple Words\n",
    "\n",
    "Just multiply the likelihood for each of the words that you have seen\n",
    "\n",
    "<img src=\"https://i.imgur.com/R5t9hi9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='P1'><h2> <img src=\"https://cdn.shopify.com/s/files/1/1200/7374/products/book_aec28e76-52ec-44ab-bc01-41df1279c89f_550x825.png?v=1473897430\" width=25 align=\"left\"> <font color=\"darkorange\"> &nbsp; Practice Calculations </font><font color=\"skyblue\"> * </font></h2></a>\n",
    "\n",
    "Let's try it out on a few sentences. From above, we have our trained probabilities\n",
    "\n",
    "$$\n",
    "P(\\text{Positive}) = \\frac{3}{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\text{Negative}) = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "\n",
    "|Word | P(W given Positive)| P(W given Negative)| P(Word)|\n",
    "|---|---|--|--|\n",
    "|`boring`|$\\frac{1}{14}$|$\\frac{3}{12}$|$\\frac{2}{12}$|\n",
    "|`dull`|$\\frac{1}{14}$ |$\\frac{2}{12}$|$\\frac{1}{12}$|\n",
    "|`enjoy`|$\\frac{3}{14}$ |$\\frac{1}{12}$|$\\frac{2}{12}$|\n",
    "|`funny`|$\\frac{2}{14}$|$\\frac{1}{12}$|$\\frac{1}{12}$|\n",
    "|`happy`|$\\frac{3}{14}$|$\\frac{1}{12}$|$\\frac{2}{12}$|\n",
    "|`hate`|$\\frac{1}{14}$|$\\frac{2}{12}$|$\\frac{1}{12}$|\n",
    "|`like`|$\\frac{3}{14}$|$\\frac{2}{12}$|$\\frac{3}{12}$|\n",
    "\n",
    "What is the positive and negative sentiment for a sentence \n",
    "\n",
    "> **\"hate dull\"**\n",
    "\n",
    "Remember that the formula is\n",
    "\n",
    "$$\n",
    "P(Positive,W) = P(Positive)\\times\\frac{P(hate|Positive)}{P(hate)}\\times\\frac{P(dull|Positive)}{P(dull)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(Negative,W) = P(Negative)\\times\\frac{P(hate|Negative)}{P(hate)}\\times\\frac{P(dull|Negative)}{P(dull)}\n",
    "$$\n",
    "\n",
    "\n",
    "Is it a negative or positive sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4408163265306122\n",
      "1.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer here\n",
    "# Calculate positive score\n",
    "# P(Positive | {\"Hate\", \"Dull\"})\n",
    "\n",
    "positive = (3/5) * ((1/14) / (1/12)) * ((1/14) / (1/12))\n",
    "\n",
    "# Calculate positive score\n",
    "\n",
    "negative = (2/5) * ((2/12) / (1/12)) * ((2/12) / (1/12))\n",
    "\n",
    "print(positive)\n",
    "print(negative)\n",
    "# If positive greater than negative, then sentence is positive\n",
    "positive > negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='2'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;2.</font><font color=\"salmon\"> Vectorizer </font> </h2></a>\n",
    "\n",
    "In order for Naive Bayes Classification to work, it would require a piece of text be transformed into numerical representation: a vector. \n",
    "\n",
    "#### Convert a Document to a Vector using `CountVectorizer`\n",
    "\n",
    "The following are the words in the corpus in the Naïve Bayes Classification example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_as_is = [\"This movie is amazing\",\n",
    "             \"I hate this movie\", \n",
    "             \"This movie is pretty good\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using SkLearn's `CountVectorizer`, we can split each sentences into individual numbers representing a bunch of 1s and 0s. To do so, use `.fit_transform` with the list as an input. \n",
    "\n",
    "To get the matrix representation, use `.A`.\n",
    "\n",
    "To get the names of each columns, use the vectorizer's `.get_feature_names()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 1 0 1]\n",
      " [0 0 1 0 1 0 1]\n",
      " [0 1 0 1 1 1 1]]\n",
      "['amazing', 'good', 'hate', 'is', 'movie', 'pretty', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(docs_as_is)\n",
    "\n",
    "print(matrix.A)\n",
    "\n",
    "column_headers = vectorizer.get_feature_names()\n",
    "print(column_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer Visualised as DataFrame \n",
    "\n",
    "This is just for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>good</th>\n",
       "      <th>hate</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>pretty</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>This movie is amazing</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I hate this movie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This movie is pretty good</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           amazing  good  hate  is  movie  pretty  this\n",
       "This movie is amazing            1     0     0   1      1       0     1\n",
       "I hate this movie                0     0     1   0      1       0     1\n",
       "This movie is pretty good        0     1     0   1      1       1     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "x = [\"This movie is amazing\",\"I hate this movie\", \"This movie is pretty good\"]\n",
    "\n",
    "results_df = pd.DataFrame(data=matrix.A, index=docs_as_is,\n",
    "                         columns=vectorizer.get_feature_names())\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'><h2><img src=\"https://images.vexels.com/media/users/3/153978/isolated/preview/483ef8b10a46e28d02293a31570c8c56-warning-sign-colored-stroke-icon-by-vexels.png\" width=23 align=\"left\"><font color=\"salmon\">&nbsp;3.</font><font color=\"salmon\"> Applied Naive Bayes - Popcorn Reviews </font> </h2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `popcorn-reviews-5k.csv` training set. Add the option `sep=\"#\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5196_9</td>\n",
       "      <td>Human Tornado (1976) is in many ways a better ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2668_9</td>\n",
       "      <td>Chilling, majestic piece of cinematic fright, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9565_3</td>\n",
       "      <td>I cant say that Wargames The Dead Code is the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10271_10</td>\n",
       "      <td>This movie should not be compared to  The Stin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5639_7</td>\n",
       "      <td>Ive read the other reviews and found some to b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review  sentiment\n",
       "0    5196_9  Human Tornado (1976) is in many ways a better ...          1\n",
       "1    2668_9  Chilling, majestic piece of cinematic fright, ...          1\n",
       "2    9565_3  I cant say that Wargames The Dead Code is the ...          0\n",
       "3  10271_10  This movie should not be compared to  The Stin...          1\n",
       "4    5639_7  Ive read the other reviews and found some to b...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "popcorn_df = pd.read_csv('popcorn-reviews-5k.csv', sep=\"#\")\n",
    "\n",
    "popcorn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split \n",
    "\n",
    "Create new data frames from the raw df, as subsets\n",
    "\n",
    "* train (first 4500 rows) as `train_df`\n",
    "* test (last 500 rows) as `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = popcorn_df[:4500]\n",
    "test_df = popcorn_df[500:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Train the model given the reviews and the given sentiment. Recall that for `sentiment`, 1 represents a positive review and 0 represents a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(train_df['review'])\n",
    "matrix.A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a multinomial classifier using the training set using the features and the training set labels\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(matrix, train_df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Now that we have trained our classifier, let's test it using the test set. We will check the actual prediction of a test example, and observe what the predicted model gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not so many people like the movies of Bertrand blier simply because they dont understand them. Simply because they are different kinds of people. SO, les valseuses is much better a name than going places. To dance a valse you need to be elegant, but going places you dont.\n",
      "actual sentiment: 1\n",
      "\n",
      "predicited sentiment: [1]\n"
     ]
    }
   ],
   "source": [
    "# Now, randomly sample an example from the test set.\n",
    "t_sample = test_df.sample()\n",
    "\n",
    "# Let's see the review in the test set and the actual sentiment, first row [0]\n",
    "s = t_sample.iloc[0]['review']\n",
    "print(s)\n",
    "t = t_sample.iloc[0]['sentiment']\n",
    "print('actual sentiment:', t)\n",
    "\n",
    "# Let's now see what class the model predicts for this test example.\n",
    "print()\n",
    "print('predicited sentiment:', classifier.predict(vectorizer.transform([s])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credits**\n",
    "- [Kaggle (Bag of Words Meets Bags of Popcorn)](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) \n",
    "\n",
    "**Footnote**\n",
    "\n",
    "(1) : The reviews are partially processed. Only removal of special characters was performed. The remaining steps to be performed are stemming and removal of stop words.\n",
    "\n",
    "**Further Reading**\n",
    "Naïve Bayes can also be used for the following classification problems:\n",
    "\n",
    "1. Spam vs. Non-Spam in E-Mail Filtering\n",
    "2. Product classification using product titles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
